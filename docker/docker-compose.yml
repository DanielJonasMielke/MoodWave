services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  spark-consumer:
    build:
      context: .. # Build from parent directory
      dockerfile: docker/Dockerfile.spark
    container_name: spark-consumer
    depends_on:
      - kafka
    volumes:
      - ../src:/app/src # Mount your code for live updates
      - ../config.yaml:/app/config.yaml
      - ../.env:/app/.env
      - spark-tmp:/tmp # Persistent volume for Spark temp files
    tmpfs:
      - /dev/shm:size=2g # Shared memory for Spark
    environment:
      - CONFIG_PATH=/app/config.yaml
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - SPARK_LOCAL_DIRS=/tmp/spark-temp
      - SPARK_WORKER_DIR=/tmp/spark-work

volumes:
  spark-tmp: